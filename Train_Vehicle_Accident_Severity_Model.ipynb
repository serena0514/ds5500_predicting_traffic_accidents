{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages and mount Drive"
      ],
      "metadata": {
        "id": "REztPHeR1UsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from geopy.distance import geodesic\n",
        "from scipy.spatial import KDTree\n",
        "import joblib"
      ],
      "metadata": {
        "id": "u1o2B3Um1KpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wcWyVAE1WuU",
        "outputId": "b4a1fdf0-e8da-44a1-971b-46cc291eb1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "-QIXY6Hj1HhV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejJlrdnW0r-b"
      },
      "outputs": [],
      "source": [
        "# Read in Boston car accident data\n",
        "filtered_file_path = '/content/drive/My Drive/Boston_US_Accidents_March23.csv'\n",
        "\n",
        "df_MA_accidents = pd.read_csv(filtered_file_path)\n",
        "\n",
        "df_MA_accidents = df_MA_accidents.drop_duplicates()\n",
        "# Crash set to 1 if accident occured; non-accident rows will have Crash set to 0\n",
        "df_MA_accidents[\"Crash\"] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find and remove or impute null values"
      ],
      "metadata": {
        "id": "BHwd7zhD1qJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = df_MA_accidents.isnull().sum()\n",
        "\n",
        "important_columns = [\n",
        "    'ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng',\n",
        "       'Distance(mi)','Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
        "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
        "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
        "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
        "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
        "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
        "       'Astronomical_Twilight', 'Crash']\n",
        "\n",
        "filtered_null_counts = null_counts[important_columns]\n",
        "\n",
        "display(filtered_null_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ywJaj_3A1xdX",
        "outputId": "053d1e07-d980-4b60-e601-565d57290e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ID                          0\n",
              "Severity                    0\n",
              "Start_Time                  0\n",
              "Start_Lat                   0\n",
              "Start_Lng                   0\n",
              "Distance(mi)                0\n",
              "Temperature(F)              0\n",
              "Wind_Chill(F)             934\n",
              "Humidity(%)                 0\n",
              "Pressure(in)                1\n",
              "Visibility(mi)              0\n",
              "Wind_Direction              0\n",
              "Wind_Speed(mph)            32\n",
              "Precipitation(in)        1342\n",
              "Weather_Condition           2\n",
              "Amenity                     0\n",
              "Bump                        0\n",
              "Crossing                    0\n",
              "Give_Way                    0\n",
              "Junction                    0\n",
              "No_Exit                     0\n",
              "Railway                     0\n",
              "Roundabout                  0\n",
              "Station                     0\n",
              "Stop                        0\n",
              "Traffic_Calming             0\n",
              "Traffic_Signal              0\n",
              "Turning_Loop                0\n",
              "Sunrise_Sunset              0\n",
              "Civil_Twilight              0\n",
              "Nautical_Twilight           0\n",
              "Astronomical_Twilight       0\n",
              "Crash                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop_nulls = ['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)','Temperature(F)', 'Humidity(%)', 'Pressure(in)','Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)','Weather_Condition', 'Amenity', 'Bump', 'Crossing','Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station','Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop','Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight','Astronomical_Twilight', 'Crash']\n",
        "\n",
        "df_MA_accidents.dropna(subset=columns_to_drop_nulls, inplace=True)"
      ],
      "metadata": {
        "id": "GjUibRL517G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume windchill is same as temp if null\n",
        "df_MA_accidents['Wind_Chill(F)'] = df_MA_accidents['Wind_Chill(F)'].fillna(df_MA_accidents['Temperature(F)'])\n",
        "\n",
        "# assume rain not present if null\n",
        "df_MA_accidents['Precipitation(in)'] = df_MA_accidents['Precipitation(in)'].fillna(0)"
      ],
      "metadata": {
        "id": "LiuxIuQ02HRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random coordinates based on Boston's range\n",
        "def generate_random_Boston_coordinates(num_samples):\n",
        "    min_lat, max_lat = 42.2279, 42.4008\n",
        "    min_lon, max_lon = -71.1912, -70.9860\n",
        "    latitudes = np.random.uniform(min_lat, max_lat, num_samples)\n",
        "    longitudes = np.random.uniform(min_lon, max_lon, num_samples)\n",
        "    return latitudes, longitudes\n",
        "\n",
        "# Generate non-accident data\n",
        "num_samples = 2000\n",
        "start_date = datetime(2016, 3, 23)\n",
        "end_date = datetime(2023, 2, 28)\n",
        "date_range = (end_date - start_date).days\n",
        "non_accidents_MA = {\n",
        "    'ID': [f'nc_{i+1}' for i in range(num_samples)],\n",
        "    'Severity': [0] * num_samples,\n",
        "    'Start_Time': [start_date + timedelta(days=random.randint(0, date_range)) for _ in range(num_samples)],\n",
        "    'Start_Lat': [],\n",
        "    'Start_Lng': [],\n",
        "    'Distance(mi)': [0] * num_samples,\n",
        "    'Description': ['No crash'] * num_samples,\n",
        "    # Columns below are initialized with placeholder; updated with merging\n",
        "    'Temperature(F)': [np.NaN] * num_samples,\n",
        "    'Wind_Chill(F)': [np.NaN] * num_samples,\n",
        "    'Humidity(%)': [np.NaN] * num_samples,\n",
        "    'Pressure(in)': [np.NaN] * num_samples,\n",
        "    'Visibility(mi)': [np.NaN] * num_samples,\n",
        "    'Wind_Speed(mph)': [np.NaN] * num_samples,\n",
        "    'Precipitation(in)': [np.NaN] * num_samples,\n",
        "    'Weather_Condition': ['Placeholder'] * num_samples,\n",
        "    'Amenity': [False] * num_samples,\n",
        "    'Bump': [False] * num_samples,\n",
        "    'Crossing': [False] * num_samples,\n",
        "    'Give_Way': [False] * num_samples,\n",
        "    'Junction': [False] * num_samples,\n",
        "    'No_Exit': [False] * num_samples,\n",
        "    'Railway': [False] * num_samples,\n",
        "    'Roundabout': [False] * num_samples,\n",
        "    'Station': [False] * num_samples,\n",
        "    'Stop': [False] * num_samples,\n",
        "    'Traffic_Calming': [False] * num_samples,\n",
        "    'Traffic_Signal': [False] * num_samples,\n",
        "    'Turning_Loop': [False] * num_samples,\n",
        "}\n",
        "\n",
        "latitudes, longitudes = generate_random_Boston_coordinates(num_samples)\n",
        "non_accidents_MA['Start_Lat'] = latitudes\n",
        "non_accidents_MA['Start_Lng'] = longitudes\n",
        "\n",
        "# Set Crash to 0 where accident did not occur\n",
        "non_accidents_MA[\"Crash\"] = 0\n",
        "df_non_accidents_MA = pd.DataFrame(non_accidents_MA)"
      ],
      "metadata": {
        "id": "rWwCVb1j2RlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T/F column imputation for non-accident rows"
      ],
      "metadata": {
        "id": "y_fPMkvw3HX7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCW2haPyUoDD"
      },
      "outputs": [],
      "source": [
        "# Round the coordinates to 3 decimal places; original 6 decimals too precise\n",
        "df_MA_accidents['Start_Lat_Rounded'] = df_MA_accidents['Start_Lat'].round(3)\n",
        "df_MA_accidents['Start_Lng_Rounded'] = df_MA_accidents['Start_Lng'].round(3)\n",
        "df_non_accidents_MA['Start_Lat_Rounded'] = df_non_accidents_MA['Start_Lat'].round(3)\n",
        "df_non_accidents_MA['Start_Lng_Rounded'] = df_non_accidents_MA['Start_Lng'].round(3)\n",
        "\n",
        "# List of True/False columns\n",
        "true_false_columns = ['Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop']\n",
        "\n",
        "# Merge datasets using coordinates\n",
        "merged_df = pd.merge(df_non_accidents_MA, df_MA_accidents[['Start_Lat_Rounded', 'Start_Lng_Rounded'] + true_false_columns],\n",
        "                     on=['Start_Lat_Rounded', 'Start_Lng_Rounded'],\n",
        "                     how='left',\n",
        "                     suffixes=('', '_acc'))\n",
        "\n",
        "# Update True/False columns in artificial dataset\n",
        "for col in true_false_columns:\n",
        "    merged_df[col] = merged_df[col] | merged_df[col + '_acc']\n",
        "\n",
        "df_non_accidents_MA = merged_df.drop(columns=['Start_Lat_Rounded', 'Start_Lng_Rounded'] + [col + '_acc' for col in true_false_columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge accident and non-accident data"
      ],
      "metadata": {
        "id": "jhTsmtVr3yTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unneccessary columns from accidents data\n",
        "df_MA_accidents.drop(columns=['End_Time','End_Lat','End_Lng','Source','Street','City','County','State','Zipcode','Country','Timezone','Airport_Code',\n",
        "                              'Weather_Timestamp','Wind_Direction','Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight'], inplace=True)\n",
        "\n",
        "df_all_instances_MA = pd.concat([df_MA_accidents, df_non_accidents_MA], ignore_index=True)"
      ],
      "metadata": {
        "id": "VWR_CgMP3qu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop any columns where location, date and time are the same, as this would make the non-accident row invalid\n",
        "duplicate_mask = df_all_instances_MA.duplicated(subset=['Start_Lat','Start_Lng','Start_Time'], keep=False)\n",
        "\n",
        "df_all_instances_MA = df_all_instances_MA[~duplicate_mask]"
      ],
      "metadata": {
        "id": "QqcGFfbj39_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical weather-related imputation for non-accident rows"
      ],
      "metadata": {
        "id": "5DC_rWcj5Xmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward fill categorical colum\n",
        "df_all_instances_MA['Weather_Condition'] = df_all_instances_MA['Weather_Condition'].ffill()"
      ],
      "metadata": {
        "id": "4fx1qEmf5h7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Start_Time is in datetime format\n",
        "df_all_instances_MA['Start_Time'] = pd.to_datetime(df_all_instances_MA['Start_Time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "# Sort DataFrame by Start_Time\n",
        "df_all_instances_MA.sort_values(by='Start_Time', inplace=True)\n",
        "\n",
        "# Create function to impute data with closest location and start_time\n",
        "def fill_missing_with_closest(df, time_col, value_col):\n",
        "    for i in range(len(df)):\n",
        "        if pd.isna(df.iloc[i][value_col]):\n",
        "            # Determine closest previous non-null value\n",
        "            previous_index = df.iloc[:i][value_col].last_valid_index()\n",
        "            previous_value = df.at[previous_index, value_col] if previous_index is not None else np.nan\n",
        "            previous_time = df.at[previous_index, time_col] if previous_index is not None else pd.NaT\n",
        "\n",
        "            # Determine closest next non-null value\n",
        "            next_index = df.iloc[i+1:][value_col].first_valid_index()\n",
        "            next_value = df.at[next_index, value_col] if next_index is not None else np.nan\n",
        "            next_time = df.at[next_index, time_col] if next_index is not None else pd.NaT\n",
        "\n",
        "            # Compare distances and select nearest neighbor\n",
        "            if pd.isna(previous_value):\n",
        "                df.at[df.index[i], value_col] = next_value\n",
        "            elif pd.isna(next_value):\n",
        "                df.at[df.index[i], value_col] = previous_value\n",
        "            else:\n",
        "                previous_time_diff = abs(df.iloc[i][time_col] - previous_time) if previous_time is not pd.NaT else pd.Timedelta.max\n",
        "                next_time_diff = abs(df.iloc[i][time_col] - next_time) if next_time is not pd.NaT else pd.Timedelta.max\n",
        "                df.at[df.index[i], value_col] = previous_value if previous_time_diff <= next_time_diff else next_value\n",
        "    return df"
      ],
      "metadata": {
        "id": "tGi1HSVM5pvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run function on numeric columns\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Temperature(F)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Wind_Chill(F)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Humidity(%)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Pressure(in)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Visibility(mi)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Wind_Speed(mph)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Precipitation(in)')"
      ],
      "metadata": {
        "id": "jIFQ9pAy6KXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pull in IMPACT Boston data from MA gov to pull road surface conditions"
      ],
      "metadata": {
        "id": "aT7QXspG6uJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import road surface data\n",
        "road_surface_MA = '/content/drive/My Drive/MA_road_surface_conditions.xlsx'\n",
        "df_road_surface_conditions_MA = pd.read_excel(road_surface_MA)"
      ],
      "metadata": {
        "id": "EK5egLw26Z1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_road_surface_conditions_MA['Crash Date'] = df_road_surface_conditions_MA['Crash Date'].astype(str)\n",
        "df_road_surface_conditions_MA['Crash Time'] = df_road_surface_conditions_MA['Crash Time'].astype(str)\n",
        "\n",
        "# Remove rows without Crash Date and Crash Time 'Crash Date' or 'Crash Time'\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA[df_road_surface_conditions_MA['Crash Date'] != 'nan']\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA[df_road_surface_conditions_MA['Crash Time'] != 'nan']\n",
        "\n",
        "# Concatenate date and time and ensure proper format\n",
        "df_road_surface_conditions_MA['Crash_DateTime'] = pd.to_datetime(df_road_surface_conditions_MA['Crash Date'] + ' ' + df_road_surface_conditions_MA['Crash Time'], errors='coerce')\n",
        "\n",
        "# Remove rows with null locations and times\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA.dropna(subset=['Crash_DateTime'])\n",
        "\n",
        "df_all_instances_MA['Start_Lat_Rounded'] = df_all_instances_MA['Start_Lat'].round(3)\n",
        "df_all_instances_MA['Start_Lng_Rounded'] = df_all_instances_MA['Start_Lng'].round(3)\n",
        "df_road_surface_conditions_MA['Latitude_Rounded'] = df_road_surface_conditions_MA['Latitude'].round(3)\n",
        "df_road_surface_conditions_MA['Longitude_Rounded'] = df_road_surface_conditions_MA['Longitude'].round(3)\n",
        "\n",
        "# Remove rows with invalid latitude, longitude, or datetime based on overlap\n",
        "df_all_instances_MA = df_all_instances_MA.dropna(subset=['Start_Lat_Rounded', 'Start_Lng_Rounded', 'Start_Time'])\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA.dropna(subset=['Latitude_Rounded', 'Longitude_Rounded', 'Crash_DateTime'])\n",
        "\n",
        "# Build a KDTree for spatial lookup\n",
        "coords_road = df_road_surface_conditions_MA[['Latitude_Rounded', 'Longitude_Rounded']].values\n",
        "tree = KDTree(coords_road)\n",
        "\n",
        "# Prepare time data for broadcasting\n",
        "time_road = df_road_surface_conditions_MA['Crash_DateTime'].values.astype('datetime64[s]')\n",
        "time_all = df_all_instances_MA['Start_Time'].values.astype('datetime64[s]')\n",
        "\n",
        "# Find the nearest spatial neighbors\n",
        "coords_all = df_all_instances_MA[['Start_Lat_Rounded', 'Start_Lng_Rounded']].values\n",
        "distances, indices = tree.query(coords_all)\n",
        "\n",
        "# Calculate temporal distances\n",
        "temporal_distances = np.abs(time_all[:, None] - time_road[indices]).astype('timedelta64[s]').astype(int)\n",
        "\n",
        "# Combine distances\n",
        "combined_distances = distances + temporal_distances\n",
        "\n",
        "# Select the closest matches\n",
        "closest_indices = combined_distances.argmin(axis=1)\n",
        "\n",
        "# Add the closest road surface condition to df_all_instances_MA\n",
        "df_all_instances_MA['Road_Surface_Condition'] = df_road_surface_conditions_MA.iloc[closest_indices]['Road Surface Condition'].values\n",
        "\n",
        "df_all_instances_MA.drop(columns=['Start_Lat_Rounded', 'Start_Lng_Rounded'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJsOI5N5Ev5K",
        "outputId": "74b6139c-a8c0-4fc5-9cca-1f4fad869646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-13ffe33fc02c>:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_road_surface_conditions_MA['Crash_DateTime'] = pd.to_datetime(df_road_surface_conditions_MA['Crash Date'] + ' ' + df_road_surface_conditions_MA['Crash Time'], errors='coerce')\n",
            "<ipython-input-21-13ffe33fc02c>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Road_Surface_Condition'] = df_road_surface_conditions_MA.iloc[closest_indices]['Road Surface Condition'].values\n",
            "<ipython-input-21-13ffe33fc02c>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA.drop(columns=['Start_Lat_Rounded', 'Start_Lng_Rounded'], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only take in most select most common categories to eliminate outliers\n",
        "df_all_instances_MA = df_all_instances_MA[df_all_instances_MA['Road_Surface_Condition'].isin(['Wet','Dry','Ice','Snow'])]"
      ],
      "metadata": {
        "id": "TM6z5DvS7reL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Variables"
      ],
      "metadata": {
        "id": "W1OpiWRq8jr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical columns With multiple options\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df_all_instances_MA['Weather_Condition'] = label_encoder.fit_transform(df_all_instances_MA['Weather_Condition'])\n",
        "df_all_instances_MA['Road_Surface_Condition'] = label_encoder.fit_transform(df_all_instances_MA['Road_Surface_Condition'])\n",
        "\n",
        "\n",
        "# T/F columns\n",
        "\n",
        "df_all_instances_MA['Amenity'] = df_all_instances_MA['Amenity'].astype(int)\n",
        "df_all_instances_MA['Bump'] = df_all_instances_MA['Bump'].astype(int)\n",
        "df_all_instances_MA['Crossing'] = df_all_instances_MA['Crossing'].astype(int)\n",
        "df_all_instances_MA['Give_Way'] = df_all_instances_MA['Give_Way'].astype(int)\n",
        "df_all_instances_MA['Junction'] = df_all_instances_MA['Junction'].astype(int)\n",
        "df_all_instances_MA['No_Exit'] = df_all_instances_MA['No_Exit'].astype(int)\n",
        "df_all_instances_MA['Railway'] = df_all_instances_MA['Railway'].astype(int)\n",
        "df_all_instances_MA['Roundabout'] = df_all_instances_MA['Roundabout'].astype(int)\n",
        "df_all_instances_MA['Station'] = df_all_instances_MA['Station'].astype(int)\n",
        "df_all_instances_MA['Stop'] = df_all_instances_MA['Stop'].astype(int)\n",
        "df_all_instances_MA['Traffic_Calming'] = df_all_instances_MA['Traffic_Calming'].astype(int)\n",
        "df_all_instances_MA['Traffic_Signal'] = df_all_instances_MA['Traffic_Signal'].astype(int)\n",
        "df_all_instances_MA['Turning_Loop'] = df_all_instances_MA['Turning_Loop'].astype(int)"
      ],
      "metadata": {
        "id": "ix542abd8fgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract date time information"
      ],
      "metadata": {
        "id": "XHRIIWNr89o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_instances_MA['Start_Time'] = pd.to_datetime(df_all_instances_MA['Start_Time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "df_all_instances_MA['Year_Start_Time'] = df_all_instances_MA['Start_Time'].dt.year\n",
        "df_all_instances_MA['Month_Start_Time'] = df_all_instances_MA['Start_Time'].dt.month\n",
        "df_all_instances_MA['Day_Start_Time'] = df_all_instances_MA['Start_Time'].dt.day\n",
        "df_all_instances_MA['Hour_Start_Time'] = df_all_instances_MA['Start_Time'].dt.hour\n",
        "df_all_instances_MA['Minute_Start_Time'] = df_all_instances_MA['Start_Time'].dt.minute\n",
        "df_all_instances_MA['Second_Start_Time'] = df_all_instances_MA['Start_Time'].dt.second\n",
        "df_all_instances_MA['DayOfWeek_Start_Time'] = df_all_instances_MA['Start_Time'].dt.dayofweek"
      ],
      "metadata": {
        "id": "0HHjuD6t87PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build initial regression models"
      ],
      "metadata": {
        "id": "3ccX8UW49JFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unneccessary columns\n",
        "df_all_instances_MA.drop(columns=['ID','Start_Time','Description','Crash'], inplace=True)"
      ],
      "metadata": {
        "id": "xPthz3Jn9Gcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "y = df_all_instances_MA['Severity']\n",
        "df_all_instances_MA.drop(columns=['Severity'], inplace=True)\n",
        "x = df_all_instances_MA\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=14)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_train, y_train)\n",
        "y_pred = logreg.predict(x_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)\n",
        "\n",
        "coefficients = pd.DataFrame({'Feature': x.columns, 'Coefficient': logreg.coef_[0]})\n",
        "print(coefficients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IURInuAv9QYT",
        "outputId": "b4af5766-f4d5-4351-fe74-d0fd57d9d228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7724137931034483\n",
            "Accuracy: 0.7724137931034483\n",
            "Confusion Matrix:\n",
            "[[390   0   0   0   0]\n",
            " [  0   0  24   0   0]\n",
            " [  4   0 618   0   0]\n",
            " [  4   0 259   0   0]\n",
            " [  0   0   6   0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       390\n",
            "           1       0.00      0.00      0.00        24\n",
            "           2       0.68      0.99      0.81       622\n",
            "           3       0.00      0.00      0.00       263\n",
            "           4       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.77      1305\n",
            "   macro avg       0.33      0.40      0.36      1305\n",
            "weighted avg       0.62      0.77      0.68      1305\n",
            "\n",
            "                   Feature  Coefficient\n",
            "0                Start_Lat    -0.000316\n",
            "1                Start_Lng    -0.000284\n",
            "2             Distance(mi)    -0.001325\n",
            "3           Temperature(F)    -0.002905\n",
            "4            Wind_Chill(F)    -0.002316\n",
            "5              Humidity(%)    -0.003734\n",
            "6             Pressure(in)     0.000131\n",
            "7           Visibility(mi)     0.001632\n",
            "8          Wind_Speed(mph)    -0.000131\n",
            "9        Precipitation(in)    -0.000013\n",
            "10       Weather_Condition     0.110552\n",
            "11                 Amenity    -0.002577\n",
            "12                    Bump    -0.000020\n",
            "13                Crossing    -0.004628\n",
            "14                Give_Way    -0.000051\n",
            "15                Junction    -0.000687\n",
            "16                 No_Exit    -0.000021\n",
            "17                 Railway    -0.000656\n",
            "18              Roundabout     0.000000\n",
            "19                 Station    -0.001740\n",
            "20                    Stop    -0.000580\n",
            "21         Traffic_Calming    -0.000020\n",
            "22          Traffic_Signal    -0.003404\n",
            "23            Turning_Loop     0.000000\n",
            "24  Road_Surface_Condition     0.000211\n",
            "25         Year_Start_Time     0.000864\n",
            "26        Month_Start_Time    -0.000923\n",
            "27          Day_Start_Time    -0.001810\n",
            "28         Hour_Start_Time    -0.105311\n",
            "29       Minute_Start_Time    -0.221710\n",
            "30       Second_Start_Time    -0.218415\n",
            "31    DayOfWeek_Start_Time     0.008469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple linear regression\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "linear_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = linear_reg.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "coefficients = pd.DataFrame({'Feature': x.columns, 'Coefficient': linear_reg.coef_})\n",
        "print(\"Coefficients:\\n\", coefficients)\n",
        "print(\"Intercept:\", linear_reg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmybQcFN9bKx",
        "outputId": "47f9638f-ef99-44e7-c5f0-9e1738d5e67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.3726517545542554\n",
            "R^2 Score: 0.7064339234088775\n",
            "Coefficients:\n",
            "                    Feature   Coefficient\n",
            "0                Start_Lat  3.794789e+00\n",
            "1                Start_Lng  2.017970e+00\n",
            "2             Distance(mi)  1.411528e-01\n",
            "3           Temperature(F)  1.451342e-02\n",
            "4            Wind_Chill(F) -1.353748e-02\n",
            "5              Humidity(%)  3.007791e-03\n",
            "6             Pressure(in)  7.002151e-02\n",
            "7           Visibility(mi)  1.000457e-02\n",
            "8          Wind_Speed(mph) -3.669303e-03\n",
            "9        Precipitation(in)  2.930411e-01\n",
            "10       Weather_Condition -1.288487e-02\n",
            "11                 Amenity -5.285428e-02\n",
            "12                    Bump -6.564790e-02\n",
            "13                Crossing -1.282667e-01\n",
            "14                Give_Way -9.896633e-02\n",
            "15                Junction  1.310328e-01\n",
            "16                 No_Exit  1.333611e-01\n",
            "17                 Railway  8.713387e-02\n",
            "18              Roundabout  6.661338e-16\n",
            "19                 Station -7.139864e-02\n",
            "20                    Stop -5.542292e-02\n",
            "21         Traffic_Calming -6.564790e-02\n",
            "22          Traffic_Signal  4.346313e-02\n",
            "23            Turning_Loop -1.110223e-16\n",
            "24  Road_Surface_Condition  2.305391e-03\n",
            "25         Year_Start_Time -5.870583e-02\n",
            "26        Month_Start_Time -6.526791e-03\n",
            "27          Day_Start_Time  2.903657e-04\n",
            "28         Hour_Start_Time  6.990929e-02\n",
            "29       Minute_Start_Time  1.276270e-02\n",
            "30       Second_Start_Time  1.241262e-02\n",
            "31    DayOfWeek_Start_Time -2.586070e-02\n",
            "Intercept: 99.77571928354735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest regression\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf_reg.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "feature_importances = pd.DataFrame({'Feature': x.columns, 'Importance': rf_reg.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "print(\"Feature Importances:\\n\", feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXSbDwOm9not",
        "outputId": "b7e582f6-d8b4-4761-ea37-bb6dfde9047b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.08389034482758621\n",
            "R^2 Score: 0.9339132069178939\n",
            "Feature Importances:\n",
            "                    Feature  Importance\n",
            "28         Hour_Start_Time    0.862042\n",
            "1                Start_Lng    0.027053\n",
            "0                Start_Lat    0.019899\n",
            "13                Crossing    0.014415\n",
            "25         Year_Start_Time    0.010651\n",
            "2             Distance(mi)    0.008146\n",
            "30       Second_Start_Time    0.006725\n",
            "29       Minute_Start_Time    0.005538\n",
            "26        Month_Start_Time    0.005509\n",
            "6             Pressure(in)    0.005479\n",
            "27          Day_Start_Time    0.004686\n",
            "5              Humidity(%)    0.004441\n",
            "8          Wind_Speed(mph)    0.004307\n",
            "4            Wind_Chill(F)    0.003596\n",
            "3           Temperature(F)    0.003226\n",
            "31    DayOfWeek_Start_Time    0.003043\n",
            "10       Weather_Condition    0.002990\n",
            "11                 Amenity    0.001689\n",
            "19                 Station    0.001225\n",
            "7           Visibility(mi)    0.000925\n",
            "9        Precipitation(in)    0.000844\n",
            "22          Traffic_Signal    0.000793\n",
            "24  Road_Surface_Condition    0.000719\n",
            "17                 Railway    0.000672\n",
            "14                Give_Way    0.000656\n",
            "15                Junction    0.000573\n",
            "20                    Stop    0.000156\n",
            "16                 No_Exit    0.000003\n",
            "18              Roundabout    0.000000\n",
            "21         Traffic_Calming    0.000000\n",
            "23            Turning_Loop    0.000000\n",
            "12                    Bump    0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final random forest regression model after feature selection"
      ],
      "metadata": {
        "id": "I4HXdGH_96hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df_all_instances_MA[['Road_Surface_Condition','Start_Lat','Start_Lng','Hour_Start_Time','Crossing','Second_Start_Time','Minute_Start_Time','Month_Start_Time','Pressure(in)','Day_Start_Time','Humidity(%)','Wind_Chill(F)',\n",
        "                         'Temperature(F)','Weather_Condition','Amenity','Station','Visibility(mi)','Precipitation(in)','Traffic_Signal','Railway','Give_Way','Junction','Stop']]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=14)\n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=14)\n",
        "\n",
        "rf_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf_reg.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zDyIm2L9vOH",
        "outputId": "6e1704d7-8ca4-4bd7-91c2-c75fed4161f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.10451601532567048\n",
            "R^2 Score: 0.9176648004869984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save final model in Google Drive\n",
        "model_path = '/content/drive/My Drive/random_forest_accident_likelihood_model.pkl'\n",
        "\n",
        "# Save model\n",
        "joblib.dump(rf_reg, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fD1EZY2A2pg",
        "outputId": "58915b64-a93b-4c1e-b679-8b20d728a020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/random_forest_accident_likelihood_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}