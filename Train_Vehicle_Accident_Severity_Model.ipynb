{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages and mount Drive"
      ],
      "metadata": {
        "id": "REztPHeR1UsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from geopy.distance import geodesic\n",
        "from scipy.spatial import KDTree\n",
        "import joblib"
      ],
      "metadata": {
        "id": "u1o2B3Um1KpZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wcWyVAE1WuU",
        "outputId": "b900b6b1-fe70-4c41-bc5e-f0498b01f8ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "-QIXY6Hj1HhV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ejJlrdnW0r-b"
      },
      "outputs": [],
      "source": [
        "# Read in Boston car accident data\n",
        "filtered_file_path = '/content/drive/My Drive/Boston_US_Accidents_March23.csv'\n",
        "\n",
        "df_MA_accidents = pd.read_csv(filtered_file_path)\n",
        "\n",
        "df_MA_accidents = df_MA_accidents.drop_duplicates()\n",
        "# Crash set to 1 if accident occured; non-accident rows will have Crash set to 0\n",
        "df_MA_accidents[\"Crash\"] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find and remove or impute null values"
      ],
      "metadata": {
        "id": "BHwd7zhD1qJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = df_MA_accidents.isnull().sum()\n",
        "\n",
        "important_columns = [\n",
        "    'ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng',\n",
        "       'Distance(mi)','Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
        "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
        "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
        "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
        "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
        "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
        "       'Astronomical_Twilight', 'Crash']\n",
        "\n",
        "filtered_null_counts = null_counts[important_columns]\n",
        "\n",
        "display(filtered_null_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ywJaj_3A1xdX",
        "outputId": "ab98a01d-5005-433c-dfa0-081e60626e0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ID                          0\n",
              "Severity                    0\n",
              "Start_Time                  0\n",
              "Start_Lat                   0\n",
              "Start_Lng                   0\n",
              "Distance(mi)                0\n",
              "Temperature(F)              0\n",
              "Wind_Chill(F)             934\n",
              "Humidity(%)                 0\n",
              "Pressure(in)                1\n",
              "Visibility(mi)              0\n",
              "Wind_Direction              0\n",
              "Wind_Speed(mph)            32\n",
              "Precipitation(in)        1342\n",
              "Weather_Condition           2\n",
              "Amenity                     0\n",
              "Bump                        0\n",
              "Crossing                    0\n",
              "Give_Way                    0\n",
              "Junction                    0\n",
              "No_Exit                     0\n",
              "Railway                     0\n",
              "Roundabout                  0\n",
              "Station                     0\n",
              "Stop                        0\n",
              "Traffic_Calming             0\n",
              "Traffic_Signal              0\n",
              "Turning_Loop                0\n",
              "Sunrise_Sunset              0\n",
              "Civil_Twilight              0\n",
              "Nautical_Twilight           0\n",
              "Astronomical_Twilight       0\n",
              "Crash                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop_nulls = ['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)','Temperature(F)', 'Humidity(%)', 'Pressure(in)','Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)','Weather_Condition', 'Amenity', 'Bump', 'Crossing','Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station','Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop','Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight','Astronomical_Twilight', 'Crash']\n",
        "\n",
        "df_MA_accidents.dropna(subset=columns_to_drop_nulls, inplace=True)"
      ],
      "metadata": {
        "id": "GjUibRL517G8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume windchill is same as temp if null\n",
        "df_MA_accidents['Wind_Chill(F)'] = df_MA_accidents['Wind_Chill(F)'].fillna(df_MA_accidents['Temperature(F)'])\n",
        "\n",
        "# assume rain not present if null\n",
        "df_MA_accidents['Precipitation(in)'] = df_MA_accidents['Precipitation(in)'].fillna(0)"
      ],
      "metadata": {
        "id": "LiuxIuQ02HRI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random coordinates based on Boston's range\n",
        "def generate_random_Boston_coordinates(num_samples):\n",
        "    min_lat, max_lat = 42.2279, 42.4008\n",
        "    min_lon, max_lon = -71.1912, -70.9860\n",
        "    latitudes = np.random.uniform(min_lat, max_lat, num_samples)\n",
        "    longitudes = np.random.uniform(min_lon, max_lon, num_samples)\n",
        "    return latitudes, longitudes\n",
        "\n",
        "# Generate non-accident data\n",
        "num_samples = 2000\n",
        "start_date = datetime(2016, 3, 23)\n",
        "end_date = datetime(2023, 2, 28)\n",
        "date_range = (end_date - start_date).days\n",
        "non_accidents_MA = {\n",
        "    'ID': [f'nc_{i+1}' for i in range(num_samples)],\n",
        "    'Severity': [0] * num_samples,\n",
        "    'Start_Time': [start_date + timedelta(days=random.randint(0, date_range)) for _ in range(num_samples)],\n",
        "    'Start_Lat': [],\n",
        "    'Start_Lng': [],\n",
        "    'Distance(mi)': [0] * num_samples,\n",
        "    'Description': ['No crash'] * num_samples,\n",
        "    # Columns below are initialized with placeholder; updated with merging\n",
        "    'Temperature(F)': [np.NaN] * num_samples,\n",
        "    'Wind_Chill(F)': [np.NaN] * num_samples,\n",
        "    'Humidity(%)': [np.NaN] * num_samples,\n",
        "    'Pressure(in)': [np.NaN] * num_samples,\n",
        "    'Visibility(mi)': [np.NaN] * num_samples,\n",
        "    'Wind_Speed(mph)': [np.NaN] * num_samples,\n",
        "    'Precipitation(in)': [np.NaN] * num_samples,\n",
        "    'Weather_Condition': ['Placeholder'] * num_samples,\n",
        "    'Amenity': [False] * num_samples,\n",
        "    'Bump': [False] * num_samples,\n",
        "    'Crossing': [False] * num_samples,\n",
        "    'Give_Way': [False] * num_samples,\n",
        "    'Junction': [False] * num_samples,\n",
        "    'No_Exit': [False] * num_samples,\n",
        "    'Railway': [False] * num_samples,\n",
        "    'Roundabout': [False] * num_samples,\n",
        "    'Station': [False] * num_samples,\n",
        "    'Stop': [False] * num_samples,\n",
        "    'Traffic_Calming': [False] * num_samples,\n",
        "    'Traffic_Signal': [False] * num_samples,\n",
        "    'Turning_Loop': [False] * num_samples,\n",
        "}\n",
        "\n",
        "latitudes, longitudes = generate_random_Boston_coordinates(num_samples)\n",
        "non_accidents_MA['Start_Lat'] = latitudes\n",
        "non_accidents_MA['Start_Lng'] = longitudes\n",
        "\n",
        "# Set Crash to 0 where accident did not occur\n",
        "non_accidents_MA[\"Crash\"] = 0\n",
        "df_non_accidents_MA = pd.DataFrame(non_accidents_MA)"
      ],
      "metadata": {
        "id": "rWwCVb1j2RlG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T/F column imputation for non-accident rows"
      ],
      "metadata": {
        "id": "y_fPMkvw3HX7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pCW2haPyUoDD"
      },
      "outputs": [],
      "source": [
        "# Round the coordinates to 3 decimal places; original 6 decimals too precise\n",
        "df_MA_accidents['Start_Lat_Rounded'] = df_MA_accidents['Start_Lat'].round(3)\n",
        "df_MA_accidents['Start_Lng_Rounded'] = df_MA_accidents['Start_Lng'].round(3)\n",
        "df_non_accidents_MA['Start_Lat_Rounded'] = df_non_accidents_MA['Start_Lat'].round(3)\n",
        "df_non_accidents_MA['Start_Lng_Rounded'] = df_non_accidents_MA['Start_Lng'].round(3)\n",
        "\n",
        "# List of True/False columns\n",
        "true_false_columns = ['Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop']\n",
        "\n",
        "# Merge datasets using coordinates\n",
        "merged_df = pd.merge(df_non_accidents_MA, df_MA_accidents[['Start_Lat_Rounded', 'Start_Lng_Rounded'] + true_false_columns],\n",
        "                     on=['Start_Lat_Rounded', 'Start_Lng_Rounded'],\n",
        "                     how='left',\n",
        "                     suffixes=('', '_acc'))\n",
        "\n",
        "# Update True/False columns in artificial dataset\n",
        "for col in true_false_columns:\n",
        "    merged_df[col] = merged_df[col] | merged_df[col + '_acc']\n",
        "\n",
        "df_non_accidents_MA = merged_df.drop(columns=['Start_Lat_Rounded', 'Start_Lng_Rounded'] + [col + '_acc' for col in true_false_columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge accident and non-accident data"
      ],
      "metadata": {
        "id": "jhTsmtVr3yTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unneccessary columns from accidents data\n",
        "df_MA_accidents.drop(columns=['End_Time','End_Lat','End_Lng','Source','Street','City','County','State','Zipcode','Country','Timezone','Airport_Code',\n",
        "                              'Weather_Timestamp','Wind_Direction','Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight'], inplace=True)\n",
        "\n",
        "df_all_instances_MA = pd.concat([df_MA_accidents, df_non_accidents_MA], ignore_index=True)"
      ],
      "metadata": {
        "id": "VWR_CgMP3qu4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop any columns where location, date and time are the same, as this would make the non-accident row invalid\n",
        "duplicate_mask = df_all_instances_MA.duplicated(subset=['Start_Lat','Start_Lng','Start_Time'], keep=False)\n",
        "\n",
        "df_all_instances_MA = df_all_instances_MA[~duplicate_mask]"
      ],
      "metadata": {
        "id": "QqcGFfbj39_z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical weather-related imputation for non-accident rows"
      ],
      "metadata": {
        "id": "5DC_rWcj5Xmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward fill categorical colum\n",
        "df_all_instances_MA['Weather_Condition'] = df_all_instances_MA['Weather_Condition'].ffill()"
      ],
      "metadata": {
        "id": "4fx1qEmf5h7A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Start_Time is in datetime format\n",
        "df_all_instances_MA['Start_Time'] = pd.to_datetime(df_all_instances_MA['Start_Time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "# Sort DataFrame by Start_Time\n",
        "df_all_instances_MA.sort_values(by='Start_Time', inplace=True)\n",
        "\n",
        "# Create function to impute data with closest location and start_time\n",
        "def fill_missing_with_closest(df, time_col, value_col):\n",
        "    for i in range(len(df)):\n",
        "        if pd.isna(df.iloc[i][value_col]):\n",
        "            # Determine closest previous non-null value\n",
        "            previous_index = df.iloc[:i][value_col].last_valid_index()\n",
        "            previous_value = df.at[previous_index, value_col] if previous_index is not None else np.nan\n",
        "            previous_time = df.at[previous_index, time_col] if previous_index is not None else pd.NaT\n",
        "\n",
        "            # Determine closest next non-null value\n",
        "            next_index = df.iloc[i+1:][value_col].first_valid_index()\n",
        "            next_value = df.at[next_index, value_col] if next_index is not None else np.nan\n",
        "            next_time = df.at[next_index, time_col] if next_index is not None else pd.NaT\n",
        "\n",
        "            # Compare distances and select nearest neighbor\n",
        "            if pd.isna(previous_value):\n",
        "                df.at[df.index[i], value_col] = next_value\n",
        "            elif pd.isna(next_value):\n",
        "                df.at[df.index[i], value_col] = previous_value\n",
        "            else:\n",
        "                previous_time_diff = abs(df.iloc[i][time_col] - previous_time) if previous_time is not pd.NaT else pd.Timedelta.max\n",
        "                next_time_diff = abs(df.iloc[i][time_col] - next_time) if next_time is not pd.NaT else pd.Timedelta.max\n",
        "                df.at[df.index[i], value_col] = previous_value if previous_time_diff <= next_time_diff else next_value\n",
        "    return df"
      ],
      "metadata": {
        "id": "tGi1HSVM5pvl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run function on numeric columns\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Temperature(F)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Wind_Chill(F)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Humidity(%)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Pressure(in)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Visibility(mi)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Wind_Speed(mph)')\n",
        "df_all_instances_MA = fill_missing_with_closest(df_all_instances_MA, 'Start_Time', 'Precipitation(in)')"
      ],
      "metadata": {
        "id": "jIFQ9pAy6KXU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pull in IMPACT Boston data from MA gov to pull road surface conditions"
      ],
      "metadata": {
        "id": "aT7QXspG6uJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import road surface data\n",
        "road_surface_MA = '/content/drive/My Drive/MA_road_surface_conditions.xlsx'\n",
        "df_road_surface_conditions_MA = pd.read_excel(road_surface_MA)"
      ],
      "metadata": {
        "id": "EK5egLw26Z1B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_road_surface_conditions_MA['Crash Date'] = df_road_surface_conditions_MA['Crash Date'].astype(str)\n",
        "df_road_surface_conditions_MA['Crash Time'] = df_road_surface_conditions_MA['Crash Time'].astype(str)\n",
        "\n",
        "# Remove rows without Crash Date and Crash Time 'Crash Date' or 'Crash Time'\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA[df_road_surface_conditions_MA['Crash Date'] != 'nan']\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA[df_road_surface_conditions_MA['Crash Time'] != 'nan']\n",
        "\n",
        "# Concatenate date and time and ensure proper format\n",
        "df_road_surface_conditions_MA['Crash_DateTime'] = pd.to_datetime(df_road_surface_conditions_MA['Crash Date'] + ' ' + df_road_surface_conditions_MA['Crash Time'], errors='coerce')\n",
        "\n",
        "# Remove rows with null locations and times\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA.dropna(subset=['Crash_DateTime'])\n",
        "\n",
        "df_all_instances_MA['Start_Lat_Rounded'] = df_all_instances_MA['Start_Lat'].round(3)\n",
        "df_all_instances_MA['Start_Lng_Rounded'] = df_all_instances_MA['Start_Lng'].round(3)\n",
        "df_road_surface_conditions_MA['Latitude_Rounded'] = df_road_surface_conditions_MA['Latitude'].round(3)\n",
        "df_road_surface_conditions_MA['Longitude_Rounded'] = df_road_surface_conditions_MA['Longitude'].round(3)\n",
        "\n",
        "# Remove rows with invalid latitude, longitude, or datetime based on overlap\n",
        "df_all_instances_MA = df_all_instances_MA.dropna(subset=['Start_Lat_Rounded', 'Start_Lng_Rounded', 'Start_Time'])\n",
        "df_road_surface_conditions_MA = df_road_surface_conditions_MA.dropna(subset=['Latitude_Rounded', 'Longitude_Rounded', 'Crash_DateTime'])\n",
        "\n",
        "# Build a KDTree for spatial lookup\n",
        "coords_road = df_road_surface_conditions_MA[['Latitude_Rounded', 'Longitude_Rounded']].values\n",
        "tree = KDTree(coords_road)\n",
        "\n",
        "# Prepare time data for broadcasting\n",
        "time_road = df_road_surface_conditions_MA['Crash_DateTime'].values.astype('datetime64[s]')\n",
        "time_all = df_all_instances_MA['Start_Time'].values.astype('datetime64[s]')\n",
        "\n",
        "# Find the nearest spatial neighbors\n",
        "coords_all = df_all_instances_MA[['Start_Lat_Rounded', 'Start_Lng_Rounded']].values\n",
        "distances, indices = tree.query(coords_all)\n",
        "\n",
        "# Calculate temporal distances\n",
        "temporal_distances = np.abs(time_all[:, None] - time_road[indices]).astype('timedelta64[s]').astype(int)\n",
        "\n",
        "# Combine distances\n",
        "combined_distances = distances + temporal_distances\n",
        "\n",
        "# Select the closest matches\n",
        "closest_indices = combined_distances.argmin(axis=1)\n",
        "\n",
        "# Add the closest road surface condition to df_all_instances_MA\n",
        "df_all_instances_MA['Road_Surface_Condition'] = df_road_surface_conditions_MA.iloc[closest_indices]['Road Surface Condition'].values\n",
        "\n",
        "df_all_instances_MA.drop(columns=['Start_Lat_Rounded', 'Start_Lng_Rounded'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJsOI5N5Ev5K",
        "outputId": "5d08b860-fa1d-4bcc-a009-5cb62f25f19b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-17611ddbaadb>:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_road_surface_conditions_MA['Crash_DateTime'] = pd.to_datetime(df_road_surface_conditions_MA['Crash Date'] + ' ' + df_road_surface_conditions_MA['Crash Time'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only take in most select most common categories to eliminate outliers\n",
        "df_all_instances_MA = df_all_instances_MA[df_all_instances_MA['Road_Surface_Condition'].isin(['Wet','Dry','Ice','Snow'])]"
      ],
      "metadata": {
        "id": "TM6z5DvS7reL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Variables"
      ],
      "metadata": {
        "id": "W1OpiWRq8jr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical columns With multiple options\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df_all_instances_MA['Weather_Condition'] = label_encoder.fit_transform(df_all_instances_MA['Weather_Condition'])\n",
        "df_all_instances_MA['Road_Surface_Condition'] = label_encoder.fit_transform(df_all_instances_MA['Road_Surface_Condition'])\n",
        "\n",
        "\n",
        "# T/F columns\n",
        "\n",
        "df_all_instances_MA['Amenity'] = df_all_instances_MA['Amenity'].astype(int)\n",
        "df_all_instances_MA['Bump'] = df_all_instances_MA['Bump'].astype(int)\n",
        "df_all_instances_MA['Crossing'] = df_all_instances_MA['Crossing'].astype(int)\n",
        "df_all_instances_MA['Give_Way'] = df_all_instances_MA['Give_Way'].astype(int)\n",
        "df_all_instances_MA['Junction'] = df_all_instances_MA['Junction'].astype(int)\n",
        "df_all_instances_MA['No_Exit'] = df_all_instances_MA['No_Exit'].astype(int)\n",
        "df_all_instances_MA['Railway'] = df_all_instances_MA['Railway'].astype(int)\n",
        "df_all_instances_MA['Roundabout'] = df_all_instances_MA['Roundabout'].astype(int)\n",
        "df_all_instances_MA['Station'] = df_all_instances_MA['Station'].astype(int)\n",
        "df_all_instances_MA['Stop'] = df_all_instances_MA['Stop'].astype(int)\n",
        "df_all_instances_MA['Traffic_Calming'] = df_all_instances_MA['Traffic_Calming'].astype(int)\n",
        "df_all_instances_MA['Traffic_Signal'] = df_all_instances_MA['Traffic_Signal'].astype(int)\n",
        "df_all_instances_MA['Turning_Loop'] = df_all_instances_MA['Turning_Loop'].astype(int)"
      ],
      "metadata": {
        "id": "ix542abd8fgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b77160-9a23-41fc-f0bc-0e962b79dd10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-10ba123a6c29>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Weather_Condition'] = label_encoder.fit_transform(df_all_instances_MA['Weather_Condition'])\n",
            "<ipython-input-17-10ba123a6c29>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Road_Surface_Condition'] = label_encoder.fit_transform(df_all_instances_MA['Road_Surface_Condition'])\n",
            "<ipython-input-17-10ba123a6c29>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Amenity'] = df_all_instances_MA['Amenity'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Bump'] = df_all_instances_MA['Bump'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Crossing'] = df_all_instances_MA['Crossing'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Give_Way'] = df_all_instances_MA['Give_Way'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Junction'] = df_all_instances_MA['Junction'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['No_Exit'] = df_all_instances_MA['No_Exit'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Railway'] = df_all_instances_MA['Railway'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Roundabout'] = df_all_instances_MA['Roundabout'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Station'] = df_all_instances_MA['Station'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Stop'] = df_all_instances_MA['Stop'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Traffic_Calming'] = df_all_instances_MA['Traffic_Calming'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Traffic_Signal'] = df_all_instances_MA['Traffic_Signal'].astype(int)\n",
            "<ipython-input-17-10ba123a6c29>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Turning_Loop'] = df_all_instances_MA['Turning_Loop'].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract date time information"
      ],
      "metadata": {
        "id": "XHRIIWNr89o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_instances_MA['Start_Time'] = pd.to_datetime(df_all_instances_MA['Start_Time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "df_all_instances_MA['Year_Start_Time'] = df_all_instances_MA['Start_Time'].dt.year\n",
        "df_all_instances_MA['Month_Start_Time'] = df_all_instances_MA['Start_Time'].dt.month\n",
        "df_all_instances_MA['Day_Start_Time'] = df_all_instances_MA['Start_Time'].dt.day\n",
        "df_all_instances_MA['Hour_Start_Time'] = df_all_instances_MA['Start_Time'].dt.hour\n",
        "df_all_instances_MA['Minute_Start_Time'] = df_all_instances_MA['Start_Time'].dt.minute\n",
        "df_all_instances_MA['Second_Start_Time'] = df_all_instances_MA['Start_Time'].dt.second\n",
        "df_all_instances_MA['DayOfWeek_Start_Time'] = df_all_instances_MA['Start_Time'].dt.dayofweek"
      ],
      "metadata": {
        "id": "0HHjuD6t87PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e19bd2-ae2e-4195-b652-2d5b563c7983"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-5a898076ab4a>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Start_Time'] = pd.to_datetime(df_all_instances_MA['Start_Time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
            "<ipython-input-18-5a898076ab4a>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Year_Start_Time'] = df_all_instances_MA['Start_Time'].dt.year\n",
            "<ipython-input-18-5a898076ab4a>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Month_Start_Time'] = df_all_instances_MA['Start_Time'].dt.month\n",
            "<ipython-input-18-5a898076ab4a>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Day_Start_Time'] = df_all_instances_MA['Start_Time'].dt.day\n",
            "<ipython-input-18-5a898076ab4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Hour_Start_Time'] = df_all_instances_MA['Start_Time'].dt.hour\n",
            "<ipython-input-18-5a898076ab4a>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Minute_Start_Time'] = df_all_instances_MA['Start_Time'].dt.minute\n",
            "<ipython-input-18-5a898076ab4a>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['Second_Start_Time'] = df_all_instances_MA['Start_Time'].dt.second\n",
            "<ipython-input-18-5a898076ab4a>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA['DayOfWeek_Start_Time'] = df_all_instances_MA['Start_Time'].dt.dayofweek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build initial regression models"
      ],
      "metadata": {
        "id": "3ccX8UW49JFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unneccessary columns\n",
        "df_all_instances_MA.drop(columns=['ID','Start_Time','Description','Crash'], inplace=True)"
      ],
      "metadata": {
        "id": "xPthz3Jn9Gcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e749820-1df6-4e09-a981-469bc210e22f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-b1bf82662c17>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA.drop(columns=['ID','Start_Time','Description','Crash'], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "y = df_all_instances_MA['Severity']\n",
        "df_all_instances_MA.drop(columns=['Severity'], inplace=True)\n",
        "x = df_all_instances_MA\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=14)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_train, y_train)\n",
        "y_pred = logreg.predict(x_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)\n",
        "\n",
        "coefficients = pd.DataFrame({'Feature': x.columns, 'Coefficient': logreg.coef_[0]})\n",
        "print(coefficients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IURInuAv9QYT",
        "outputId": "616e6ed6-33f1-407f-83dc-45033b54eff3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-d3e5f16b52b9>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_all_instances_MA.drop(columns=['Severity'], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.786042944785276\n",
            "Accuracy: 0.786042944785276\n",
            "Confusion Matrix:\n",
            "[[398   0   0   0   0]\n",
            " [  0   0  27   0   0]\n",
            " [  1   0 627   0   0]\n",
            " [  2   0 245   0   0]\n",
            " [  0   0   4   0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       398\n",
            "           1       0.00      0.00      0.00        27\n",
            "           2       0.69      1.00      0.82       628\n",
            "           3       0.00      0.00      0.00       247\n",
            "           4       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.79      1304\n",
            "   macro avg       0.34      0.40      0.36      1304\n",
            "weighted avg       0.64      0.79      0.70      1304\n",
            "\n",
            "                   Feature  Coefficient\n",
            "0                Start_Lat    -0.000384\n",
            "1                Start_Lng    -0.000302\n",
            "2             Distance(mi)    -0.001611\n",
            "3           Temperature(F)    -0.001196\n",
            "4            Wind_Chill(F)    -0.000785\n",
            "5              Humidity(%)    -0.005283\n",
            "6             Pressure(in)     0.000215\n",
            "7           Visibility(mi)     0.001273\n",
            "8          Wind_Speed(mph)    -0.002652\n",
            "9        Precipitation(in)    -0.000004\n",
            "10       Weather_Condition     0.123478\n",
            "11                 Amenity    -0.003055\n",
            "12                    Bump    -0.000033\n",
            "13                Crossing    -0.005432\n",
            "14                Give_Way    -0.000050\n",
            "15                Junction    -0.000862\n",
            "16                 No_Exit    -0.000023\n",
            "17                 Railway    -0.000755\n",
            "18              Roundabout     0.000000\n",
            "19                 Station    -0.001977\n",
            "20                    Stop    -0.000643\n",
            "21         Traffic_Calming    -0.000033\n",
            "22          Traffic_Signal    -0.004060\n",
            "23            Turning_Loop     0.000000\n",
            "24  Road_Surface_Condition     0.000262\n",
            "25         Year_Start_Time     0.000753\n",
            "26        Month_Start_Time    -0.002541\n",
            "27          Day_Start_Time     0.002606\n",
            "28         Hour_Start_Time    -0.122552\n",
            "29       Minute_Start_Time    -0.238614\n",
            "30       Second_Start_Time    -0.235533\n",
            "31    DayOfWeek_Start_Time     0.008966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple linear regression\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "linear_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = linear_reg.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "coefficients = pd.DataFrame({'Feature': x.columns, 'Coefficient': linear_reg.coef_})\n",
        "print(\"Coefficients:\\n\", coefficients)\n",
        "print(\"Intercept:\", linear_reg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmybQcFN9bKx",
        "outputId": "37f9c522-a69b-4f2c-fc51-acc04b59027d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.359311907664662\n",
            "R^2 Score: 0.7133574617812052\n",
            "Coefficients:\n",
            "                    Feature   Coefficient\n",
            "0                Start_Lat  3.710987e+00\n",
            "1                Start_Lng  1.829879e+00\n",
            "2             Distance(mi)  1.290018e-01\n",
            "3           Temperature(F)  8.381691e-03\n",
            "4            Wind_Chill(F) -8.192793e-03\n",
            "5              Humidity(%)  3.454368e-03\n",
            "6             Pressure(in)  8.622581e-02\n",
            "7           Visibility(mi)  1.206123e-02\n",
            "8          Wind_Speed(mph) -7.721972e-04\n",
            "9        Precipitation(in)  4.530440e-01\n",
            "10       Weather_Condition -1.244375e-02\n",
            "11                 Amenity -5.998241e-02\n",
            "12                    Bump -7.498700e-04\n",
            "13                Crossing -1.125172e-01\n",
            "14                Give_Way -3.321535e-02\n",
            "15                Junction  1.635439e-01\n",
            "16                 No_Exit  1.708626e-01\n",
            "17                 Railway  8.615075e-02\n",
            "18              Roundabout -6.661338e-16\n",
            "19                 Station -8.765948e-02\n",
            "20                    Stop -9.618532e-02\n",
            "21         Traffic_Calming -7.498700e-04\n",
            "22          Traffic_Signal  4.803718e-02\n",
            "23            Turning_Loop -5.551115e-17\n",
            "24  Road_Surface_Condition  1.628542e-03\n",
            "25         Year_Start_Time -6.012894e-02\n",
            "26        Month_Start_Time -3.337723e-03\n",
            "27          Day_Start_Time -5.849829e-04\n",
            "28         Hour_Start_Time  7.216371e-02\n",
            "29       Minute_Start_Time  1.309611e-02\n",
            "30       Second_Start_Time  1.178207e-02\n",
            "31    DayOfWeek_Start_Time -2.123844e-02\n",
            "Intercept: 92.26935591588142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest regression\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf_reg.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "feature_importances = pd.DataFrame({'Feature': x.columns, 'Importance': rf_reg.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "print(\"Feature Importances:\\n\", feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXSbDwOm9not",
        "outputId": "aec5f683-0c22-423b-ce4c-130f97789809"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.08325268404907975\n",
            "R^2 Score: 0.9335848321185416\n",
            "Feature Importances:\n",
            "                    Feature  Importance\n",
            "28         Hour_Start_Time    0.861326\n",
            "1                Start_Lng    0.026132\n",
            "0                Start_Lat    0.020295\n",
            "13                Crossing    0.015375\n",
            "25         Year_Start_Time    0.011016\n",
            "2             Distance(mi)    0.007555\n",
            "29       Minute_Start_Time    0.006276\n",
            "30       Second_Start_Time    0.005707\n",
            "6             Pressure(in)    0.005624\n",
            "5              Humidity(%)    0.005225\n",
            "26        Month_Start_Time    0.005175\n",
            "27          Day_Start_Time    0.004794\n",
            "8          Wind_Speed(mph)    0.004268\n",
            "10       Weather_Condition    0.003461\n",
            "4            Wind_Chill(F)    0.003437\n",
            "3           Temperature(F)    0.003412\n",
            "31    DayOfWeek_Start_Time    0.003325\n",
            "11                 Amenity    0.001768\n",
            "7           Visibility(mi)    0.000919\n",
            "19                 Station    0.000879\n",
            "9        Precipitation(in)    0.000852\n",
            "24  Road_Surface_Condition    0.000766\n",
            "15                Junction    0.000739\n",
            "22          Traffic_Signal    0.000606\n",
            "14                Give_Way    0.000509\n",
            "17                 Railway    0.000358\n",
            "20                    Stop    0.000198\n",
            "16                 No_Exit    0.000001\n",
            "18              Roundabout    0.000000\n",
            "21         Traffic_Calming    0.000000\n",
            "23            Turning_Loop    0.000000\n",
            "12                    Bump    0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final random forest regression model after feature selection"
      ],
      "metadata": {
        "id": "I4HXdGH_96hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df_all_instances_MA[['Road_Surface_Condition','Start_Lat','Start_Lng','Hour_Start_Time','Crossing','Second_Start_Time','Minute_Start_Time','Month_Start_Time','Day_Start_Time',\n",
        "                         'Amenity','Station','Traffic_Signal','Railway','Give_Way','Junction','Stop']]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=14)\n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=14)\n",
        "\n",
        "rf_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf_reg.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zDyIm2L9vOH",
        "outputId": "2efa48e2-4fed-4d9f-fed6-91e663f13f80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.10129363496932517\n",
            "R^2 Score: 0.9191925900209429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save final model in Google Drive\n",
        "model_path = '/content/drive/My Drive/random_forest_accident_likelihood_model.pkl'\n",
        "\n",
        "# Save model\n",
        "joblib.dump(rf_reg, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fD1EZY2A2pg",
        "outputId": "dcdf0ee7-7623-4293-aa63-901b9d6814d4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/random_forest_accident_likelihood_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zr3rJBEKe5Th"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}